# 분산학습
- 여기선 이 PlaceRecognition에서 다루고 있는 부분만 공부

## Data Parallelism
- 학습해야 할 데이터가 많은 상황
- 여러 GPU에 데이터를 나눠서 학습
- 속도 향상

### Synchronization
- 위의 방법의 단점 : 가중치 업데이트
- 여러 GPU가 학습한 후 weight parameter가 다 다름
- weight parameter를 모두 모아서 평균을 낸 후 다시 나눠줘야함
- synchronization은 일종의 데이터 교환
- GPU간의 데이터 전송 속도가 빠르면 synchronization에 드는 시간도 줄음

## Model Parallelism
- 이 방법은 데이터 말고 모델 파라미터를 여러 GPU에 나누어 연산


### Tensor Parallelism
- 큰 weight matrix를 여러 GPU로 나누어 연산, 그 결과값을 합침
- $$각\ 결과값의\ 행 = weight\ matrix\ row \times Input\ Column$$
- weight matrix를 행을 기준으로 나누어 여러 GPU에서 동일한 input에 대해 곱함 ->결과값들을 붙여서 합. => 원래의 결과값이 나옴
- 학습시간이 단축됨

### Pipeline Parallelism
- 레이어 혹은 그 안의 스테이지를 각각 다른 GPU에 나눠서 학습
